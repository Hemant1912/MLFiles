{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "colab": {
      "name": "CT III Year.Convolutional_Neural_Networks-checkpoint.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hemant1912/MLFiles/blob/main/CT_III_Year_Convolutional_Neural_Networks_checkpoint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHDWb8jzkqI3"
      },
      "source": [
        "# Part 1: Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eAxVZg8kqI6"
      },
      "source": [
        "###  Importing packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CSTapDRkqI9"
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.mobilenet import MobileNet\n",
        "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "from keras.models import Model\n",
        "import timeit\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "3otQrU4JWLej"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEKUqkgGkqJI"
      },
      "source": [
        "### Preparing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtwFbXyskqJL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e2886a3-bd0b-4626-97b2-b8926fe486c8"
      },
      "source": [
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 30\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test =to_categorical(y_test, num_classes)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2A1KfUskqJT"
      },
      "source": [
        "### Building a Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMtSvqMdkqJV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0e108bf-f0b5-4362-b47e-daa538a27d06"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(8, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 8)         80        \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 8)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 16)        1168      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 5, 5, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 5, 5, 16)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 400)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                12832     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,410\n",
            "Trainable params: 14,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Aab-hxdkqJc"
      },
      "source": [
        "### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MWvDXQgkqJf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b26b792-a0c0-437c-b917-879b8e5ffec8"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "           \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1875/1875 [==============================] - 20s 6ms/step - loss: 0.6327 - accuracy: 0.7912 - val_loss: 0.1215 - val_accuracy: 0.9653\n",
            "Epoch 2/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3144 - accuracy: 0.9010 - val_loss: 0.0871 - val_accuracy: 0.9731\n",
            "Epoch 3/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2631 - accuracy: 0.9198 - val_loss: 0.0718 - val_accuracy: 0.9772\n",
            "Epoch 4/30\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2416 - accuracy: 0.9268 - val_loss: 0.0637 - val_accuracy: 0.9793\n",
            "Epoch 5/30\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2355 - accuracy: 0.9296 - val_loss: 0.0652 - val_accuracy: 0.9796\n",
            "Epoch 6/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2246 - accuracy: 0.9334 - val_loss: 0.0737 - val_accuracy: 0.9775\n",
            "Epoch 7/30\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2283 - accuracy: 0.9332 - val_loss: 0.0655 - val_accuracy: 0.9810\n",
            "Epoch 8/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2234 - accuracy: 0.9352 - val_loss: 0.0647 - val_accuracy: 0.9813\n",
            "Epoch 9/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2288 - accuracy: 0.9328 - val_loss: 0.0620 - val_accuracy: 0.9814\n",
            "Epoch 10/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2281 - accuracy: 0.9333 - val_loss: 0.0813 - val_accuracy: 0.9781\n",
            "Epoch 11/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2291 - accuracy: 0.9346 - val_loss: 0.0661 - val_accuracy: 0.9825\n",
            "Epoch 12/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2402 - accuracy: 0.9325 - val_loss: 0.0637 - val_accuracy: 0.9819\n",
            "Epoch 13/30\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2444 - accuracy: 0.9303 - val_loss: 0.0684 - val_accuracy: 0.9805\n",
            "Epoch 14/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2418 - accuracy: 0.9305 - val_loss: 0.0751 - val_accuracy: 0.9793\n",
            "Epoch 15/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2566 - accuracy: 0.9293 - val_loss: 0.0694 - val_accuracy: 0.9802\n",
            "Epoch 16/30\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2535 - accuracy: 0.9291 - val_loss: 0.0943 - val_accuracy: 0.9764\n",
            "Epoch 17/30\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2555 - accuracy: 0.9281 - val_loss: 0.0754 - val_accuracy: 0.9807\n",
            "Epoch 18/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2578 - accuracy: 0.9295 - val_loss: 0.0756 - val_accuracy: 0.9779\n",
            "Epoch 19/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2704 - accuracy: 0.9263 - val_loss: 0.0766 - val_accuracy: 0.9823\n",
            "Epoch 20/30\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2737 - accuracy: 0.9255 - val_loss: 0.1076 - val_accuracy: 0.9742\n",
            "Epoch 21/30\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2716 - accuracy: 0.9270 - val_loss: 0.0931 - val_accuracy: 0.9764\n",
            "Epoch 22/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2794 - accuracy: 0.9254 - val_loss: 0.0879 - val_accuracy: 0.9753\n",
            "Epoch 23/30\n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.2807 - accuracy: 0.9246 - val_loss: 0.0808 - val_accuracy: 0.9823\n",
            "Epoch 24/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2795 - accuracy: 0.9245 - val_loss: 0.0845 - val_accuracy: 0.9806\n",
            "Epoch 25/30\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2844 - accuracy: 0.9239 - val_loss: 0.0850 - val_accuracy: 0.9802\n",
            "Epoch 26/30\n",
            " 739/1875 [==========>...................] - ETA: 5s - loss: 0.2916 - accuracy: 0.9211"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gprccy28kqJn"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74OuyWUkkqJq"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScMO1hxHkqJw"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHv0D_xhkqJx"
      },
      "source": [
        "import pylab as plt\n",
        "\n",
        "plt.imshow(x_test[122].reshape(28,28),cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "li=[0.5, 0,0.4, 0,0,0]\n",
        "li=np.array(li)\n",
        "thresholded = (li>=0.5)*1\n",
        "thresholded "
      ],
      "metadata": {
        "id": "HFYYp7JEaHoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "7ffffzwBkqJ3"
      },
      "source": [
        "import numpy as np\n",
        "prediction = model.predict(x_test[122:123])\n",
        "print('Prediction Score:\\n',prediction[0])\n",
        "thresholded = (prediction>0.5)*1\n",
        "print('\\nThresholded Score:\\n',thresholded[0])\n",
        "print('\\nPredicted Digit:\\n',np.where(thresholded == 1)[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKT5OJSVkqJ8"
      },
      "source": [
        "# Part 2: Applications of Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzUY5QxykqJ_"
      },
      "source": [
        "###  MobileNet Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVPVmwIZkqKA"
      },
      "source": [
        "model = MobileNet(input_shape=None, alpha=0.25, depth_multiplier=1, dropout=1e-3, \n",
        "                                 include_top=True, weights='imagenet', input_tensor=None, pooling=None, classes=1000)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaGjhRRmkqKI"
      },
      "source": [
        "###  Classify images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTFWBD9FkqKK"
      },
      "source": [
        "# Write the image name below\n",
        "\n",
        "img_path = '.jpg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "preds = model.predict(x)\n",
        "print('Predicted:\\n', decode_predictions(preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvvQWG_8kqKQ"
      },
      "source": [
        "###  Extract CNN features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rT0iPnxkqKS"
      },
      "source": [
        "features = model.predict(x)\n",
        "print('\\nFeature Shape:\\n',features.shape)\n",
        "print('\\nFeatures:\\n',features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYHHR_bskqKY"
      },
      "source": [
        "###  Extract features from an arbitrary intermediate layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOrIUA2DkqKb"
      },
      "source": [
        "model_minimal = Model(input=model.input, output=model.get_layer('conv_dw_2_relu').output)\n",
        "\n",
        "conv_dw_2_relu_features = model_minimal.predict(x)\n",
        "print('Features of conv_dw_2_relu:',conv_dw_2_relu_features.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oPYajJZkqKh"
      },
      "source": [
        "### You can extract these features and use the base network as a feature extractor for your problems. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5z5cFn5kqKj"
      },
      "source": [
        "# Part 3: Deep Convolution Layer Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yjr6DcimkqKm"
      },
      "source": [
        "import matplotlib as mp\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow.contrib.slim as slim\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOMgk22xkqKr"
      },
      "source": [
        "### Extract Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6PBNav6kqKt"
      },
      "source": [
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-nifFGhkqKy"
      },
      "source": [
        "### Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "9LkN_paDkqKz"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "x = tf.placeholder(tf.float32, [None, 784],name=\"x-in\")\n",
        "true_y = tf.placeholder(tf.float32, [None, 10],name=\"y-in\")\n",
        "keep_prob = tf.placeholder(\"float\")\n",
        "\n",
        "x_image = tf.reshape(x,[-1,28,28,1])\n",
        "hidden_1 = slim.conv2d(x_image,5,[5,5])\n",
        "pool_1 = slim.max_pool2d(hidden_1,[2,2])\n",
        "hidden_2 = slim.conv2d(pool_1,5,[5,5])\n",
        "pool_2 = slim.max_pool2d(hidden_2,[2,2])\n",
        "hidden_3 = slim.conv2d(pool_2,20,[5,5])\n",
        "hidden_3 = slim.dropout(hidden_3,keep_prob)\n",
        "out_y = slim.fully_connected(slim.flatten(hidden_3),10,activation_fn=tf.nn.softmax)\n",
        "\n",
        "cross_entropy = -tf.reduce_sum(true_y*tf.log(out_y))\n",
        "correct_prediction = tf.equal(tf.argmax(out_y,1), tf.argmax(true_y,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEodGsOUkqK5"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UPBduFekqK6"
      },
      "source": [
        "batchSize = 50\n",
        "sess = tf.Session()\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init)\n",
        "for i in range(1001):\n",
        "    batch = mnist.train.next_batch(batchSize)\n",
        "    sess.run(train_step, feed_dict={x:batch[0],true_y:batch[1], keep_prob:0.5})\n",
        "    if i % 100 == 0 and i != 0:\n",
        "        trainAccuracy = sess.run(accuracy, feed_dict={x:batch[0],true_y:batch[1], keep_prob:1.0})\n",
        "        print(\"step %d, training accuracy %g\"%(i, trainAccuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OTeqbaJkqLA"
      },
      "source": [
        "### Testing accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-JBoLBAkqLB"
      },
      "source": [
        "testAccuracy = sess.run(accuracy, feed_dict={x:mnist.test.images,true_y:mnist.test.labels, keep_prob:1.0})\n",
        "print(\"test accuracy %g\"%(testAccuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2BhkZBskqLI"
      },
      "source": [
        "### Get activation values and plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "8DOheo-hkqLJ"
      },
      "source": [
        "def getActivations(layer,stimuli):\n",
        "    units = sess.run(layer,feed_dict={x:np.reshape(stimuli,[1,784],order='F'),keep_prob:1.0})\n",
        "    plotNNFilter(units)\n",
        "    \n",
        "def plotNNFilter(units):\n",
        "    filters = units.shape[3]\n",
        "    plt.figure(1, figsize=(20,20))\n",
        "    n_columns = 6\n",
        "    n_rows = math.ceil(filters / n_columns) + 1\n",
        "    for i in range(filters):\n",
        "        plt.subplot(n_rows, n_columns, i+1)\n",
        "        plt.title('Filter ' + str(i))\n",
        "        plt.imshow(units[0,:,:,i], interpolation=\"nearest\", cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkoaARCnkqLO"
      },
      "source": [
        "### Input Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUdOll7bkqLQ"
      },
      "source": [
        "imageToUse = mnist.test.images[0]\n",
        "plt.imshow(np.reshape(imageToUse,[28,28]), interpolation=\"nearest\", cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oZ5UZDkkqLV"
      },
      "source": [
        "### Activation in Layer 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5dxXfvPkqLX"
      },
      "source": [
        "getActivations(hidden_1,imageToUse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ay9gNAvrkqLd"
      },
      "source": [
        "### Activation in Layer 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rlb3LGrWkqLe"
      },
      "source": [
        "getActivations(hidden_2,imageToUse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhqGvOEkkqLl"
      },
      "source": [
        "### Activation in Layer 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmkgnW5ckqLo"
      },
      "source": [
        "getActivations(hidden_3,imageToUse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0awq5VogkqLt"
      },
      "source": [
        "# Part 4: Design Choices in Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OGnsygzkqLv"
      },
      "source": [
        "## Influence of convolution size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWVCTsJPkqLy"
      },
      "source": [
        "### Model with (3 x 3) Convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5wWkLbAkqL0"
      },
      "source": [
        "K.clear_session()\n",
        "start = timeit.default_timer()   \n",
        "model = Sequential()\n",
        "model.add(Conv2D(8, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "print(\"Time Taken to run the model:\",end - start, \"seconds\")  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAuW0NOHkqL7"
      },
      "source": [
        "### Model with (7 x 7) Convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnphlXbvkqL8"
      },
      "source": [
        "# Write your code here \n",
        "\n",
        "# Use the same model design from the above cell "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "by2WASoQkqMD"
      },
      "source": [
        "## Striding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h9XyTZKkqME"
      },
      "source": [
        "### Model with (7 x 7) Convolution with 2 Steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K39I1weskqMF"
      },
      "source": [
        "start = timeit.default_timer()   \n",
        "model = Sequential()\n",
        "model.add(Conv2D(8, kernel_size=(7, 7), strides=2, activation='relu', input_shape=input_shape))\n",
        "model.add(Conv2D(16, (7, 7), strides=2, activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "print(\"Time Taken to run the model:\",end - start, \"seconds\")  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lz6_wR8GkqMK"
      },
      "source": [
        "## Padding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3kln95ykqMM"
      },
      "source": [
        "### Model with (7 x 7) Convolution with Same Padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QinhffvkkqMO"
      },
      "source": [
        "start = timeit.default_timer()   \n",
        "model = Sequential()\n",
        "model.add(Conv2D(8, kernel_size=(7, 7), strides=1, padding='same', activation='relu', input_shape=input_shape))\n",
        "model.add(Conv2D(16, (7, 7), strides=1, padding='same', activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "print(\"Time Taken to run the model:\",end - start, \"seconds\")  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLPfWDdYkqMT"
      },
      "source": [
        "## Pooling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMhAfYO0kqMV"
      },
      "source": [
        "### Model with (3 x 3) Convolution with Pooling (2 x 2) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMSL5flZkqMW"
      },
      "source": [
        "start = timeit.default_timer()   \n",
        "model = Sequential()\n",
        "model.add(Conv2D(8, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "print(\"Time Taken to run the model:\",end - start, \"seconds\")  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HsHtxt0kqMc"
      },
      "source": [
        "### Model with (3 x 3) Convolution with Pooling (3 x 3) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w9kCVL7kqMe"
      },
      "source": [
        "# Write your code here \n",
        "\n",
        "# Use the same model design from the above cell "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzV7LwepkqMn"
      },
      "source": [
        "### What are your findings?"
      ]
    }
  ]
}